{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install python-dotenv\n",
    "%pip install sentence-transformers\n",
    "%pip install huggingface_hub\n",
    "%pip install langchain_community\n",
    "%pip install langchain \n",
    "%pip install ollama\n",
    "%pip install faiss-cpu\n",
    "%pip install langchain_ollama \n",
    "%pip install chromadb\n",
    "%pip install transformers\n",
    "%pip install jq\n",
    "%pip install langchain_groq\n",
    "%pip install langchain_huggingface\n",
    "%pip install -U bitsandbytes\n",
    "%pip install langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import JSONLoader\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langdetect import detect\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from typing import List\n",
    "from langchain_core.documents import Document\n",
    "from operator import itemgetter\n",
    "from langchain_huggingface import HuggingFacePipeline\n",
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.storage import InMemoryByteStore\n",
    "from langchain.retrievers import MultiVectorRetriever\n",
    "import uuid\n",
    "\n",
    "\n",
    "from huggingface_hub import login\n",
    "login(token='your huggingface token')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your JSON file\n",
    "file_path = r\"/kaggle/input/electronics/electronics_data.json\"\n",
    "\n",
    "# Define a schema to extract each JSON object\n",
    "jq_schema = \".[]\"  # Extracts each JSON object from a list\n",
    "\n",
    "# Function to extract text and metadata\n",
    "def metadata_func(record, index):  # Add index as the second parameter\n",
    "    return {\"source\": \"json_data\", \"index\": index}\n",
    "\n",
    "\n",
    "# Load JSON data\n",
    "loader = JSONLoader(\n",
    "    file_path=file_path,\n",
    "    jq_schema=jq_schema,\n",
    "    text_content=False,  # Prevents automatic extraction as a string\n",
    "    metadata_func=metadata_func\n",
    ")\n",
    "\n",
    "# Load documents\n",
    "docs = loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "278"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len( docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groq_API_Key =os.getenv('Groq_API_Key')\n",
    "model =ChatGroq(\n",
    "    model ='gemma2-9b-it',\n",
    "    groq_api_key ='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',\n",
    "    temperature=0.1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "template=\"summarize the following document:{doc}\"\n",
    "prompt =ChatPromptTemplate.from_template(template)\n",
    "\n",
    "chain =(\n",
    "    {'doc':lambda x:x.page_content}\n",
    "    |prompt\n",
    "    |model\n",
    "    |StrOutputParser()\n",
    ")\n",
    "\n",
    "summarize=chain.batch(docs,{'max_concurrency':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a6c01625bd02>:4: LangChainDeprecationWarning: The class `HuggingFaceBgeEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_function=HuggingFaceBgeEmbeddings(model_name ='BAAI/bge-m3')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c6c772a40fa480f89ed41051af30809",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "314ce122d95a4bd4b2fcdbe9644678a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/123 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "944f0aa73dd741e28de7eb39355da6e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/15.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "773afc32bc0e4e90abc580ec07fddea0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/54.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbf727749811488aa888d8284f74bf31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/687 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "440eee02746049a3a0423bf1d47f796f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/2.27G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0933a0acc6ed40a49079f1a6b279fa19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/444 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d917c77dba34da6ac539b8304a407db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48fca72ac8c542f8beec7bdb70468634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69993e59639d42b8aae87d5c786533fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/964 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "585a84b869294acfa6c913e4a2619e54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/191 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-a6c01625bd02>:2: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectorstore =Chroma(\n"
     ]
    }
   ],
   "source": [
    "# use vectore store to index child chunks\n",
    "vectorstore =Chroma(\n",
    "    collection_name='summarise',\n",
    "    embedding_function=HuggingFaceBgeEmbeddings(model_name ='BAAI/bge-m3')\n",
    "    )\n",
    "\n",
    "# storage layer for parent documents\n",
    "store =InMemoryByteStore()\n",
    "id_key ='doc_id'\n",
    "\n",
    "retriver =MultiVectorRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    docstore=store,\n",
    "    id_key =id_key,\n",
    "    search_kwargs={'k':15}\n",
    "\n",
    ")\n",
    "\n",
    "# This ensures each document has a unique ID for retrieval.\n",
    "doc_ids = [str(uuid.uuid4()) for _ in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_doc =[Document(page_content=s,metadata={id_key:doc_ids[i]}) for i,s in enumerate(summarize)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store summary_doc in vectoredb and store original docs in memory store\n",
    "retriver.vectorstore.add_documents(summary_doc)\n",
    "retriver.docstore.mset(list(zip(doc_ids,docs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\": 272, \"name\": \"NanoTech Laptop Model 709\", \"category\": \"Tablet\", \"brand\": \"CyberWare\", \"price\": 2457.67, \"stock\": 57, \"features\": [\"Compact design\", \"Bluetooth enabled\", \"Fast charging\", \"Water resistant\"], \"warranty\": \"4 years\"}\n",
      "{\"id\": 125, \"name\": \"ElectroMax Speaker Model 663\", \"category\": \"Laptop\", \"brand\": \"NanoTech\", \"price\": 1695.35, \"stock\": 29, \"features\": [\"Wireless connectivity\", \"Compact design\", \"4K resolution\", \"AI-powered assistant\", \"Noise cancellation\"], \"warranty\": \"2 years\"}\n",
      "{\"id\": 4, \"name\": \"NextGen Router Model 627\", \"category\": \"Router\", \"brand\": \"ElectroMax\", \"price\": 1222.71, \"stock\": 457, \"features\": [\"4K resolution\", \"Fast charging\", \"Touchscreen display\", \"AI-powered assistant\", \"Wireless connectivity\"], \"warranty\": \"4 years\"}\n",
      "{\"id\": 140, \"name\": \"TechCorp Laptop Model 118\", \"category\": \"Speaker\", \"brand\": \"NextGen\", \"price\": 2659.49, \"stock\": 304, \"features\": [\"Long battery life\", \"Bluetooth enabled\", \"Touchscreen display\", \"Compact design\", \"AI-powered assistant\"], \"warranty\": \"1 years\"}\n",
      "{\"id\": 236, \"name\": \"NextGen Speaker Model 916\", \"category\": \"Laptop\", \"brand\": \"NanoTech\", \"price\": 677.91, \"stock\": 142, \"features\": [\"AI-powered assistant\", \"Long battery life\", \"4K resolution\", \"Water resistant\"], \"warranty\": \"3 years\"}\n",
      "{\"id\": 104, \"name\": \"NextGen Gaming Console Model 963\", \"category\": \"Laptop\", \"brand\": \"CyberWare\", \"price\": 996.89, \"stock\": 409, \"features\": [\"Fast charging\", \"Compact design\", \"4K resolution\", \"Wireless connectivity\"], \"warranty\": \"4 years\"}\n",
      "{\"id\": 206, \"name\": \"SmartTrend Tablet Model 105\", \"category\": \"Laptop\", \"brand\": \"GigaByte\", \"price\": 2000.43, \"stock\": 169, \"features\": [\"Fast charging\", \"Noise cancellation\", \"Wireless connectivity\", \"4K resolution\"], \"warranty\": \"2 years\"}\n",
      "{\"id\": 6, \"name\": \"ElectroMax Laptop Model 947\", \"category\": \"Tablet\", \"brand\": \"ElectroMax\", \"price\": 1588.38, \"stock\": 107, \"features\": [\"Touchscreen display\", \"Wireless connectivity\", \"Long battery life\"], \"warranty\": \"4 years\"}\n",
      "{\"id\": 35, \"name\": \"TechCorp Tablet Model 109\", \"category\": \"Laptop\", \"brand\": \"ElectroMax\", \"price\": 797.59, \"stock\": 118, \"features\": [\"Compact design\", \"Noise cancellation\", \"Long battery life\"], \"warranty\": \"3 years\"}\n",
      "{\"id\": 155, \"name\": \"ElectroMax Tablet Model 686\", \"category\": \"Router\", \"brand\": \"HyperGadgets\", \"price\": 2122.62, \"stock\": 318, \"features\": [\"AI-powered assistant\", \"Wireless connectivity\", \"Bluetooth enabled\", \"4K resolution\"], \"warranty\": \"3 years\"}\n",
      "{\"id\": 200, \"name\": \"NextGen Headphones Model 400\", \"category\": \"Laptop\", \"brand\": \"SmartTrend\", \"price\": 954.98, \"stock\": 180, \"features\": [\"AI-powered assistant\", \"Wireless connectivity\"], \"warranty\": \"1 years\"}\n",
      "{\"id\": 26, \"name\": \"Visionary Laptop Model 812\", \"category\": \"Smartwatch\", \"brand\": \"NanoTech\", \"price\": 1748.06, \"stock\": 146, \"features\": [\"Water resistant\", \"AI-powered assistant\", \"Compact design\", \"Wireless connectivity\"], \"warranty\": \"1 years\"}\n",
      "{\"id\": 229, \"name\": \"CyberWare Laptop Model 614\", \"category\": \"Laptop\", \"brand\": \"Visionary\", \"price\": 2118.45, \"stock\": 404, \"features\": [\"Touchscreen display\", \"4K resolution\", \"AI-powered assistant\", \"Bluetooth enabled\"], \"warranty\": \"4 years\"}\n",
      "{\"id\": 5, \"name\": \"NextGen Headphones Model 233\", \"category\": \"Tablet\", \"brand\": \"GigaByte\", \"price\": 2302.92, \"stock\": 490, \"features\": [\"4K resolution\", \"Wireless connectivity\", \"Touchscreen display\", \"Water resistant\", \"Fast charging\"], \"warranty\": \"3 years\"}\n",
      "{\"id\": 190, \"name\": \"NanoTech Laptop Model 840\", \"category\": \"Headphones\", \"brand\": \"Infinity\", \"price\": 1576.11, \"stock\": 137, \"features\": [\"Long battery life\", \"Noise cancellation\", \"Fast charging\", \"Bluetooth enabled\"], \"warranty\": \"2 years\"}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-27c710d51957>:1: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  retriver_doc =retriver.get_relevant_documents(\"ايه انواع اللابات المتوفرة\")\n"
     ]
    }
   ],
   "source": [
    "retriver_doc =retriver.get_relevant_documents(\"ايه انواع اللابات المتوفرة\")\n",
    "for i in range(len(retriver_doc)):\n",
    "    print(retriver_doc[i].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aya Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2754e2f050d4a208f5cdb8a07887934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/8.64k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd42e9248a5b463993acb8f3093900a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/12.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "880fb01ec9384c239a4baccbd0e20b41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/439 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9738ff0560464f10b5510626435affce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/634 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9cdd8e8302c4cdaa9c60d318d893cbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/21.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0b01e709e7c440194a763d553c7fdd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "347e2d162036447886802a892fef43bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc08e7f3a58b4bd890b984cd5bbc8132",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b1ab42be24b4fb4aaa7bda23f8ffe6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "405877287d7b4074aa01c00d6750d453",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.22G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d876e033154e4403bbb15f8c9181ea83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fd6d0799e1a42e1b40cb67e2a9edddf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline,BitsAndBytesConfig\n",
    "import torch\n",
    "# Configure 4-bit quantization\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model_name = \"CohereForAI/aya-expanse-8b\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    trust_remote_code=True,\n",
    "    quantization_config=quantization_config,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# Create the Hugging Face pipeline\n",
    "hf_pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=20000,\n",
    "    temperature=0.3,\n",
    "    return_full_text=False \n",
    ")\n",
    "\n",
    "# Wrap the pipeline\n",
    "llm = HuggingFacePipeline(pipeline=hf_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-72ccd621732a>:2: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(memory_key=\"history\", return_messages=True)\n"
     ]
    }
   ],
   "source": [
    "# Initialize memory for chat history\n",
    "memory = ConversationBufferMemory(memory_key=\"history\", return_messages=True)\n",
    "\n",
    "ar_template = \"\"\"\n",
    "إنت دلوقتي شغال وكيل مبيعات مصري محترف لشركة  الكتروفيرس وهي شركة متخصصة في صناعة  الالكترونيات مطلوب منك:\n",
    "١- تجاوب على كل الأسئلة اللي ليها علاقة بالمنتجات\n",
    "خلي اسماء المنتجات باللغة الانجليزية\n",
    "وحاول تكون اجابتك واضحة ومنظمة\n",
    "السياق بتاع المنتجات: {context}\n",
    "تاريخ المحادثة:{history}\n",
    "السؤال بتاعك: {question}\n",
    "\"\"\"\n",
    "\n",
    "en_template=\"\"\"you act as a sales man for mobica products answer\n",
    "the following question from the following context and follow this rules:\n",
    "- be organized and clear\n",
    "- reply with detials for each product\n",
    "\n",
    "question:{question}\n",
    "chat history:{history}\n",
    "context:{context}\n",
    " \"\"\"\n",
    "\n",
    "def detect_language(question):\n",
    "    language =detect(question)\n",
    "    if language =='ar':\n",
    "        return 'Arabic'\n",
    "    else:\n",
    "        return 'English'\n",
    "\n",
    "\n",
    "def format_docs(docs: List[Document]) -> str:\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Restructure the chain to ensure proper processing\n",
    "retriever_chain =(\n",
    "    retriver \n",
    "    | format_docs\n",
    ")\n",
    "\n",
    "def get_response(query):\n",
    "    # Get relevant documents\n",
    "    retrieved_docs = retriever_chain.invoke(query)\n",
    "    \n",
    "    # detect language of query\n",
    "    lang=detect_language(query)\n",
    "    if lang =='Arabic':\n",
    "       prompt = ChatPromptTemplate.from_template(ar_template)\n",
    "    else: \n",
    "       prompt = ChatPromptTemplate.from_template(en_template)\n",
    "\n",
    "    # Format the prompt with context and question\n",
    "    formatted_prompt = prompt.format(\n",
    "        context=retrieved_docs, \n",
    "        history =memory.load_memory_variables({}).get(\"history\", \"\"),\n",
    "        question=query\n",
    "    )\n",
    "    \n",
    "    # Get response from the LLM directly\n",
    "    response = llm.invoke(formatted_prompt)\n",
    "\n",
    "     # Save the new interaction to memory\n",
    "    memory.save_context({\"question\": query}, {\"response\": response})\n",
    "    \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.3` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('\\n'\n",
      " 'ردك:\\n'\n",
      " '\\n'\n",
      " 'مرحباً! يسرني مساعدتك في اختيار لابتوب مناسب لتعلم البرمجة. من بين الخيارات '\n",
      " 'المتاحة لدينا، أوصي بشدة بـ  {\"id\": 206, \"name\": \"SmartTrend Tablet Model '\n",
      " '105\", \"category\": \"Laptop\", \"brand\": \"GigaByte\", \"price\": 2000.43, \"stock\": '\n",
      " '169, \"features\": [\"Fast charging\", \"Noise cancellation\", \"Wireless '\n",
      " 'connectivity\", \"4K resolution\"], \"warranty\": \"2 years\"}  لعدة أسباب:\\n'\n",
      " '\\n'\n",
      " '- **سعر معقول:** يُعد هذا اللابتوب خيارًا ممتازًا من حيث التكلفة، حيث يقدم '\n",
      " 'مواصفات قوية بسعر 2000.43 جنيه مصري.\\n'\n",
      " '\\n'\n",
      " '- **مواصفات قوية:** يتميز بشاشة 4K عالية الدقة، وتكنولوجيا إلغاء الضوضاء، '\n",
      " 'والاتصال اللاسلكي، والشحن السريع، كلها ميزات مفيدة لتجربة برمجة سلسة.\\n'\n",
      " '\\n'\n",
      " '- **جودة العلامة التجارية:** \"GigaByte\" هي علامة تجارية معروفة بجودة '\n",
      " 'منتجاتها وموثوقيتها، لذا يمكنك الوثوق بأن هذا اللابتوب سيوفر أداءً مستقرًا '\n",
      " 'وموثوقًا.\\n'\n",
      " '\\n'\n",
      " '- **ضمان جيد:** يوفر اللابتوب ضمانًا لمدة عامين، مما يمنحك راحة البال في '\n",
      " 'حالة حدوث أي مشكلات أثناء الاستخدام.\\n'\n",
      " '\\n'\n",
      " 'بالإضافة إلى ذلك، فإن {\"id\": 104, \"name\": \"NextGen Gaming Console Model '\n",
      " '963\", \"category\": \"Laptop\", \"brand\": \"CyberWare\", \"price\": 996.89, \"stock\": '\n",
      " '409, \"features\": [\"Fast charging\", \"Compact design\", \"4K resolution\", '\n",
      " '\"Wireless connectivity\"], \"warranty\": \"4 years\"} هو أيضًا خيار قوي، خاصة إذا '\n",
      " 'كنت تبحثين عن جهاز متين مع ضمان أطول.\\n'\n",
      " '\\n'\n",
      " 'قبل اتخاذ القرار النهائي، أوصي بالآتي:\\n'\n",
      " '- مراجعة متطلبات البرمجة الخاصة بك والتأكد من أن اللابتوب يلبي هذه '\n",
      " 'الاحتياجات.\\n'\n",
      " '- قراءة مراجعات المستخدمين للحصول على نظرة ثاقبة حول تجارب الآخرين مع هذه '\n",
      " 'الأجهزة.\\n'\n",
      " '- التحقق من توفر الدعم الفني وخدمات ما بعد البيع في منطقتك.\\n'\n",
      " '\\n'\n",
      " 'أتمنى أن يساعدك هذا في اختيار اللابتوب المثالي لتعلم البرمجة. إذا كانت لديك '\n",
      " 'أي أسئلة أخرى أو كنت بحاجة إلى مزيد من التوصيات، فلا تترددي في السؤال!')\n"
     ]
    }
   ],
   "source": [
    "# Test the fixed function\n",
    "response = get_response(\"عايزة اشتري لابتوب لتعلم البرمجة\")\n",
    "from pprint import pprint\n",
    "pprint(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.3` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('\\n'\n",
      " 'ردي:\\n'\n",
      " '\\n'\n",
      " 'مرحباً! يسرني مساعدتك في اختيار لابتوب للألعاب. من بين الخيارات المتاحة '\n",
      " 'لدينا، أوصي بشدة بـ  {\"id\": 27, \"name\": \"ElectroMax Gaming Console Model '\n",
      " '470\", \"category\": \"Gaming Console\", \"brand\": \"NextGen\", \"price\": 2421.93, '\n",
      " '\"stock\": 330, \"features\": [\"AI-powered assistant\", \"Noise cancellation\", '\n",
      " '\"Touchscreen display\"], \"warranty\": \"4 years\"}  لعدة أسباب:\\n'\n",
      " '\\n'\n",
      " '- **أداء قوي:** يتميز هذا اللابتوب بمعالج قوي وذاكرة وصول عشوائي (RAM) '\n",
      " 'كبيرة، مما يضمن تجربة ألعاب سلسة وبدون تأخير.\\n'\n",
      " '\\n'\n",
      " '- **جودة الصوت:** تكنولوجيا إلغاء الضوضاء (Noise Cancellation) المدمجة توفر '\n",
      " 'تجربة صوتية غامرة أثناء اللعب.\\n'\n",
      " '\\n'\n",
      " '- **شاشة عالية الجودة:** شاشة اللمس عالية الدقة مع معدل تحديث عالٍ تضمن لك '\n",
      " 'رؤية واضحة وسلسة أثناء اللعب.\\n'\n",
      " '\\n'\n",
      " '- **ضمان موثوق:** يوفر اللابتوب ضمانًا لمدة 4 سنوات، مما يمنحك راحة البال في '\n",
      " 'حالة حدوث أي مشكلات.\\n'\n",
      " '\\n'\n",
      " 'بالإضافة إلى ذلك، إذا كنت تبحث عن خيار أكثر اقتصادًا مع مواصفات جيدة، فإن  '\n",
      " '{\"id\": 104, \"name\": \"NextGen Gaming Console Model 963\", \"category\": '\n",
      " '\"Laptop\", \"brand\": \"CyberWare\", \"price\": 996.89, \"stock\": 409, \"features\": '\n",
      " '[\"Fast charging\", \"Compact design\", \"4K resolution\", \"Wireless '\n",
      " 'connectivity\"], \"warranty\": \"4 years\"} هو أيضًا خيار رائع.\\n'\n",
      " '\\n'\n",
      " 'قبل اتخاذ القرار النهائي، أوصي بالآتي:\\n'\n",
      " '- تجربة اللابتوب شخصيًا، إن أمكن، لمعرفة ما إذا كان مريحًا لك أثناء اللعب.\\n'\n",
      " '- التحقق من توافق اللابتوب مع متطلبات الألعاب التي تخطط للعبها.\\n'\n",
      " '- قراءة مراجعات المستخدمين للحصول على آراء حول أداء اللابتوب على المدى '\n",
      " 'الطويل.\\n'\n",
      " '\\n'\n",
      " 'أتمنى أن يساعدك هذا في اختيار اللابتوب المثالي للألعاب. إذا كانت لديك أي '\n",
      " 'أسئلة أخرى، فلا تتردد في السؤال!')\n"
     ]
    }
   ],
   "source": [
    "pprint(get_response(\"عاوز اشتري لابتوب للألعاب\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.3` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('\\n'\n",
      " 'بناءً على السياق بتاع المنتجات، أنصحك بـ:\\n'\n",
      " '\\n'\n",
      " '**{\"id\": 260, \"name\": \"GigaByte Headphones Model 635\", \"category\": \"Router\", '\n",
      " '\"brand\": \"GigaByte\", \"price\": 2469.26, \"stock\": 338, \"features\": [\"Wireless '\n",
      " 'connectivity\", \"Bluetooth enabled\", \"AI-powered assistant\", \"Noise '\n",
      " 'cancellation\"], \"warranty\": \"4 years\"}**\\n'\n",
      " '\\n'\n",
      " 'السبب:\\n'\n",
      " '\\n'\n",
      " '- **الاتصال اللاسلكي:** يوفر هذا الراوتر اتصالًا لاسلكيًا قويًا، مما يحسن من '\n",
      " 'جودة الإنترنت في شقتك.\\n'\n",
      " '- **تقنية AI:** مساعد الذكاء الاصطناعي المدمج يمكنه تحسين جودة الاتصال '\n",
      " 'وتقليل التداخل.\\n'\n",
      " '- **إلغاء الضوضاء:** تكنولوجيا إلغاء الضوضاء تساعد في تقليل التشويش، مما '\n",
      " 'يؤدي إلى تجربة إنترنت أكثر سلاسة.\\n'\n",
      " '- **ضمان موثوق:** يوفر الراوتر ضمانًا لمدة 4 سنوات، مما يمنحك راحة البال.\\n'\n",
      " '\\n'\n",
      " 'قبل اتخاذ القرار النهائي، تأكدي من مراجعة متطلبات الإنترنت الخاصة بك والتأكد '\n",
      " 'من أن هذا الراوتر يلبي احتياجاتك. كما يُنصح بالتحقق من توافق الراوتر مع مزود '\n",
      " 'خدمة الإنترنت الخاص بك.\\n'\n",
      " '\\n'\n",
      " 'أتمنى أن يساعدك هذا في اختيار المنتج المناسب لتحسين جودة الإنترنت في شقتك!')\n"
     ]
    }
   ],
   "source": [
    "pprint(get_response(\"عاوزة اشتري منتج يحسن من جودة النت في الشقة\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.3` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('\\n'\n",
      " '## \\n'\n",
      " '**توصيات للعملاء المهتمين بأجهزة الكمبيوتر المحمولة:**\\n'\n",
      " '\\n'\n",
      " 'بناءً على السياق المقدم، يبدو أن العميل يبحث عن جهاز كمبيوتر محمول (لابتوب) '\n",
      " 'لأغراض مختلفة، بما في ذلك تعلم البرمجة، والألعاب، وتحسين جودة الإنترنت. فيما '\n",
      " 'يلي التوصيات المفصلة لكل سيناريو:\\n'\n",
      " '\\n'\n",
      " '**1. لابتوب لتعلم البرمجة:**\\n'\n",
      " '\\n'\n",
      " '- **GigaByte SmartTrend Tablet Model 105:** يعد هذا اللابتوب خيارًا ممتازًا '\n",
      " 'للمبتدئين في البرمجة. فهو يوفر مواصفات قوية بسعر معقول، مع شاشة 4K عالية '\n",
      " 'الدقة، وتكنولوجيا إلغاء الضوضاء، والاتصال اللاسلكي السريع. تضمن ضمانه لمدة '\n",
      " 'عامين راحة البال أثناء الاستخدام.\\n'\n",
      " '\\n'\n",
      " '- **CyberWare NextGen Gaming Console Model 963:** إذا كان ميزانيتك تسمح '\n",
      " 'بذلك، فإن هذا اللابتوب خيار قوي آخر. فهو يوفر أداءً ممتازًا، وجودة صوت '\n",
      " 'محسنة، وشاشة مريحة. ضمانه لمدة 4 سنوات يضيف طبقة إضافية من الحماية.\\n'\n",
      " '\\n'\n",
      " '**2. لابتوب للألعاب:**\\n'\n",
      " '\\n'\n",
      " '- **NextGen ElectroMax Gaming Console Model 470:** هذا اللابتوب مصمم خصيصًا '\n",
      " 'لمحبي الألعاب. فهو يقدم أداءً قويًا، وجودة صوت غامرة، وشاشة عالية الجودة. '\n",
      " 'تضمن ضمانه لمدة 4 سنوات استمرارية الأداء.\\n'\n",
      " '\\n'\n",
      " '- **CyberWare NextGen Gaming Console Model 963:** كما هو موضح أعلاه، هذا '\n",
      " 'الخيار مناسب أيضًا للألعاب، حيث يوفر مواصفات جيدة بسعر أكثر معقولية.\\n'\n",
      " '\\n'\n",
      " '**3. تحسين جودة الإنترنت (راوتر):**\\n'\n",
      " '\\n'\n",
      " '- **GigaByte Router Model 260:** يُنصح بهذا الراوتر لتحسين جودة الإنترنت في '\n",
      " 'الشقة. فهو يوفر اتصالًا لاسلكيًا قويًا، ومساعدًا ذكيًا اصطناعيًا، وتكنولوجيا '\n",
      " 'إلغاء الضوضاء لتحسين تجربة الإنترنت. ضمانه لمدة 4 سنوات يضمن موثوقية طويلة '\n",
      " 'الأمد.\\n'\n",
      " '\\n'\n",
      " 'عند اتخاذ القرار النهائي، يُنصح العميل بمراعاة متطلباته المحددة، ومقارنة '\n",
      " 'الميزات، والتحقق من توافق الأجهزة مع احتياجاته. كما أن قراءة مراجعات '\n",
      " 'المستخدمين يمكن أن توفر نظرة ثاقبة قيمة حول أداء الأجهزة وموثوقيتها.')\n"
     ]
    }
   ],
   "source": [
    "pprint(get_response('suggest labtop for busniss'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.3` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('**الحل:**\\n'\n",
      " '\\n'\n",
      " 'موبيكا لديها مجموعة واسعة من المنتجات المصممة خصيصًا لتناسب احتياجات مساحات '\n",
      " 'العمل التعاونية. فيما يلي بعض الحلول المثالية التي تقدمها موبيكا:\\n'\n",
      " '\\n'\n",
      " '- **محطات العمل الفردية (MOBICA 2000 KIDNEY-SHAPED DESK):** هذه الطاولات '\n",
      " 'الفردية ذات الشكل الكلوي مثالية لبيئات العمل التعاونية حيث توفر مساحة عمل '\n",
      " 'مريحة وشخصية. يمكن للموظفين تنظيم أجهزتهم وأدواتهم بسهولة على سطح الطاولة '\n",
      " 'الطبيعي، مع الحفاظ على بيئة عمل منظمة.\\n'\n",
      " '\\n'\n",
      " '- **خزانات التخزين (MOBICA 2000 CREDENZA):** توفر خزانات موبيكا مساحة تخزين '\n",
      " 'كافية للوثائق، والمعدات، واللوازم المكتبية الأخرى. يمكن تخصيصها لتناسب '\n",
      " 'احتياجات الفريق، مما يضمن سهولة الوصول إلى الموارد اللازمة للتعاون الفعال.\\n'\n",
      " '\\n'\n",
      " '- **كراسي العمل التعاونية (CAPO OPERATIVE LOW BACK CHAIR, NEW CAPO OPERATIVE '\n",
      " 'LOW BACK CHAIR, OMNI OPERATIVE CHAIR, SHARKO MULTI-PURPOSE CHAIR):** تتميز '\n",
      " 'كراسي موبيكا بتصميمها العملي والمريح، مما يشجع على جلسات العمل التعاونية '\n",
      " 'الطويلة. تضمن آلياتها المتعددة الوظائف، مثل الدوران 360 درجة والتعديل '\n",
      " 'الارتفاعي، راحة الموظفين أثناء العمل الجماعي.\\n'\n",
      " '\\n'\n",
      " '- **محطات العمل المشتركة (ARCO WORKSTATION, QUATRO WORKSTATION):** تم تصميم '\n",
      " 'هذه المحطات لتلبية احتياجات الفرق الأكبر حجمًا. توفر مساحة عمل مرنة يمكن '\n",
      " 'تخصيصها بسهولة لتناسب مختلف أنشطة التعاون. يمكن تكوينها مع الطاولات الفردية، '\n",
      " 'وخزانات التخزين، وكراسي مريحة لخلق بيئة عمل تعاونية فعالة.\\n'\n",
      " '\\n'\n",
      " '- **مناطق الاستراحة (COVO HABITAT OPERATIVE BREAK-OUT LOUNGE):** تُعد غرف '\n",
      " 'الاستراحة أو مناطق الاسترخاء داخل مساحة العمل التعاونية ضرورية لتعزيز '\n",
      " 'الإنتاجية والتفاعل الاجتماعي. توفر موبيكا غرفًا مصممة بشكل أنيق مع أكشاك '\n",
      " 'خاصة، وطاولات، وأرائك، لتشجيع الموظفين على الاستراحة والتواصل أثناء فترات '\n",
      " 'الراحة.\\n'\n",
      " '\\n'\n",
      " 'عند دمج هذه المنتجات، يمكن لموبيكا إنشاء مساحات عمل تعاونية ديناميكية ومرنة، '\n",
      " 'حيث يمكن للفرق العمل معًا بفعالية، والبقاء منظمين، والاستمتاع ببيئة عمل '\n",
      " 'مريحة. تضمن حلول موبيكا تلبية احتياجات مختلف الفرق، بدءًا من الفرق الصغيرة '\n",
      " 'إلى الفرق الأكبر حجمًا، مع الحفاظ على بيئة عمل إيجابية ومنتجة.')\n"
     ]
    }
   ],
   "source": [
    "pprint(get_response('ما هي حلول  موبيكا المثالية لمساحات العمل التعاونية؟'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pyngrok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml                                \n"
     ]
    }
   ],
   "source": [
    "!ngrok config add-authtoken \"2tA4jIqwhVEFywNqJvifyFYHkvD_6p82fsE12GmzQ4sXArwJ4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install fastapi nest-asyncio uvicorn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Public URL: https://93d2-34-135-252-127.ngrok-free.app\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [66]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://127.0.0.1:8004 (Press CTRL+C to quit)\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.3` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     156.199.104.51:0 - \"POST /answer HTTP/1.1\" 200 OK\n"
     ]
    }
   ],
   "source": [
    "from fastapi import FastAPI\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "import nest_asyncio\n",
    "from pyngrok import ngrok\n",
    "import uvicorn\n",
    "from pydantic import BaseModel\n",
    "from fastapi import HTTPException\n",
    "\n",
    "# Pydantic model for input and output\n",
    "class Question(BaseModel):\n",
    "    question: str\n",
    "\n",
    "class Answer(BaseModel):\n",
    "    answer: str\n",
    "\n",
    "app =FastAPI()\n",
    "\n",
    "# middlewares\n",
    "app.add_middleware(\n",
    "    CORSMiddleware, \n",
    "    allow_origins=['*'], \n",
    "    allow_credentials=True, \n",
    "    allow_methods=['*'], \n",
    "    allow_headers=['*'], \n",
    ")\n",
    "\n",
    "\n",
    "@app.post('/answer')\n",
    "async def get_answer(question: Question) -> Answer:\n",
    "    \"\"\"\n",
    "    Example post request body:\n",
    "    {\n",
    "        \"question\": \"What is the capital of France?\"\n",
    "    }\n",
    "    Example response:\n",
    "    {\n",
    "        \"answer\": \"The capital of France is Paris.\"\n",
    "    }\n",
    "    \"\"\"\n",
    "    answer = get_response(question.question)\n",
    "    return Answer(answer=answer)\n",
    "\n",
    "\n",
    "# Set up the FastAPI app to run on a public URL via ngrok\n",
    "port = 8004\n",
    "ngrok_tunnel = ngrok.connect(port)\n",
    "print(f\"Public URL: {ngrok_tunnel.public_url}\")\n",
    "\n",
    "nest_asyncio.apply()\n",
    "uvicorn.run(app, port=port)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
